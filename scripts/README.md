## Pipeline Architecture

The document describes the workflow flow, task ordering and filesystem
layout of the distributed protien analysis pipeline, and links each stage
of the workflow to the scripts in this directory that implement it.
---

## Celery Task Pipeline

Pipeline execution logic is implemented in:

```
/shared/almalinux/scripts/celery/tasks.py
```

This file defines all pipeline functions and the Celery task used during
execution. The pipeline is implemented as a sequence of Python functions. These functions are composed in order
into a single Celery task that performs the full end to end analysis for
one protein sequence.

```
make_seq_dir
→ write_fasta
→ run_s4pred
→ read_horiz
→ run_hhsearch
→ run_parser
→ upload_parsed_output
```

Each function performs one step in the pipeline and passes
a sequence specific path dictionary to the next step. Failures raise
exceptions and trigger retry behaviour for the entire sequence, not individual steps.

---

## Sequence Path Dictionary (`seq_paths`)

A single dictionary is created for each sequence in `make_seq_dir` and passed through
 all subsequent pipeline steps.

The dictionary contains sequence specific meta data and file paths:

```
run_id
seq_id
seq_dir -> path on NFS
tmp_fas -> path on NFS
tmp_horiz -> path on NFS
tmp_a3m -> path on NFS
tmp_hhr -> path on NFS
parsed_results -> path on NFS
```

These paths are consumed and the files populated by the corresponding functions in
`tasks.py`.

---

## Filesystem Layout

### Per-Run

All pipeline runs are created by `run_pipeline_host.py` under:

```
/shared/almalinux/runs/<run_id>/
```

### Per-Sequence

For each sequence the Celery task creates an isolated working directory:

```
runs/<run_id>/<sequence_id>/
├── tmp.fas
├── tmp.horiz
├── tmp.a3m
├── tmp.hhr
└── <sequence_id>_parsed.out
```

Intermediate files are generated by `run_s4pred`, `read_horiz`, and
`run_hhsearch`. Final parsed outputs are written by `run_parser` and uploaded to MinIO.

Each sequence directory is fully isolated.

### Aggregated Outputs

After all sequence tasks complete, `aggregate_results.py` produces
run level outputs under:

```
runs/<run_id>/output/
├── <run_id>_hits_output.csv
└── <run_id>_profile_output.csv
```

These files are also uploaded to MinIO.

---

## Host Submission

Pipeline runs are submitted from the host using:

```
python3 run_pipeline_host.py <experiment_ids_file> [run_name]
```

This script is responsible for:

- Reading experiment IDs
- Fetching sequences from PostgreSQL
- Creating the run directory
- Submitting one Celery task per sequence
- Submitting a Celery chord to trigger aggregation

If no run name is provided, one is generated automatically with the followin format:

```
run_YYYY-MM-DD_HH-MM-SS
```
---

## Database Driven Execution

Protein sequences are fetched from PostgreSQL.

The database schema is:

```sql
CREATE TABLE proteins (
    id TEXT PRIMARY KEY,
    payload TEXT NOT NULL
);
````

* `id` is the UniProt identifier
* `payload` stores the full FASTA entry

The database is populated automatically via Ansible using a Python script.

---

## Testing and Experiment Selection

Small test runs are run using helper scripts in this directory.

Random experiment IDs can be generated using:

```
python3 select_ids.py <input.fasta> <num_ids>
```

A wrapper script combines selection and execution:

```
python3 test_run_pipeline.py <num_ids> [run_name]
```

These scripts call `run_pipeline_host.py` and do not modify
core pipeline logic.

---

## Monitoring and Logging

### Metrics

Metrics are implemented in `metrics.py` and emitted by both the Celery task
and host submission code.

This script updates the metrics stored locally at

```
/home/almalinux/custom_metrics
```

Metrics include task counts, failures, pipeline state, and timestamps and
are scraped by Prometheus.

### Logs

Structured logs are recorded using `pipeline_logging.py`.

Celery workers run under systemd and write per worker logs to:

```
/var/log/protien_analysis_pipeline/
└── pipeline_<hostname>.log
```

Logs include task start, completion, failure, and retry events.
```